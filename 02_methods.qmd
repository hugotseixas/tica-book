# Methods {#sec-methods}

```{r}
#| label: libraries
#| include: false

library(gt)
library(lubridate)
library(tidyverse)

```

This project relies on developing a theoretical model of how and why Natural Vegetation Suppression (NVS) occurs persistently in the Amazon and Cerrado. This theoretical model is responsible to represent the mechanisms that causes the NVS. Based on the theoretical model, sociological and statistical analysis are performed to describe the causes of NVS from subjective and objective perspectives.

To employ the tasks above and accomplish the objectives (see @sec-objectives), the project is divided into four parts:

1.  Creation of the NVS theoretical model;

2.  Sociological assessment of agents related to the NVS theoretical model;

3.  Statistical analysis of data related to the NVS theoretical model;

4.  Interpretation of the results;

The first part is performed by conducting an adaptation of the Critical Realist Grounded Theory [@oliver-2011] method (which is itself an adaptation of the general Grounded Theory method). My adaptation combines the interactive engagement with data trough the acquisition and coding process, and the retroduction approach to infer causal mechanisms of NVS. The result of this process will be a theoretic model, represented by a Directed Acyclic Graph (DAG), which abstracts relationships of cause between variables.

In the second part, a sociological analysis describes how groups of interest are related to the variables from the NVS theoretical model, and what are the interactions between different groups, according to their actions and power status. The analysis will be based on Fields Theory of Bourdieu.

The third part contains the development and employment of statistical regression algorithms, that will be trained and tested using available data that are represented in the NVS theoretic model. The prediction of the models will be analyzed by machine learning interpretation techniques.

The fourth and last part is where results of both approaches (sociological and statistical analyses) will be interpreted in conjunction.

The sequence of activities that compose each part are represented in @fig-method-diagram, summarizing the method.

```{mermaid}
%%| label: fig-method-diagram
%%| fig-cap: "General workflow of the method. The activities that composes each part of the project are: (1) Literature Assessment, Experts Interviews, Theoretical Model; (2) Sociological Analysis; (3) Available Data, Database Structuring, Statistical Analysis; (4) Results Interpretation."
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Literature Assessment] --> B[Theoretical Model]
    C[Experts Interviews] --> B
    B --> D[Database Structuring]
    E[Available Data] --> D
    B --> F[Sociological Analysis]
    C --> G[Statistical Analysis]
    D --> G
    F --> H[Results Interpretation]
    G --> H

```

The combination of activities configures as a Convergent Parallel Mixed Method of research, where quantitative and qualitative analysis are perform at the same time, providing results to a final interpretation, However, the design of this work includes a previous establishment of a common theory that guides both analysis, so they share the same foundations.

In the next sections, each part of the work, and its respective activities are described.

## Theoretical Model

The theoretical model will be created by the employment of an adaptation of the Critical Realist Grounded Theory. The method of Grounded Theory is widely used in social sciences with the objective of generating theories, it consists of an interactive and concurrent process of data collection and analysis. It have been modified trough time to accommodate different paradigms of research, such as the Critical Realism.

The Critical Realist Grounded Theory introduces the necessity to explicitly account for the link between observations and their underlying generative mechanisms, and the use of retroduction in order to abstract these mechanisms [@oliver-2011].

The process of data acquisition is performed by a series of interviews and literature assessment. The interviews inquire possible causes of NVS and the social groups related to this phenomena. After each interview, the answers are coded into general terms, and with related question of how and why they can affect NVS. These questions are transformed into literature database queries, that helps finding written material that may enrich analysis with convergences or divergences with interview answers, or with new causes of NVS. After each round of interviews and literature assessment, the next interview may change to accommodate findings from the previous. This cyclic process is demonstrated in @fig-theoretical-diagram.

```{mermaid}
%%| label: fig-theoretical-diagram
%%| fig-cap: Workflow of theoretical model development
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Interview] --> B[Data]
    C[Questions] --> D[Literature Assessment]
    D --> E[Data]
    B --> F[Theoretical Model]
    F --> C
    E --> F
    F --> A

```

This process is repeated until the data from interviews and literature assessment starts to get redundant, adding little additional information to the theoretical model.

### Experts Interviews

The objective of the interviews is to explore a diverse range of possible causes of NVS, and its impacts on the environment and society.

The target participants are researchers with past experience on analyzing NVS in the Amazon or Cerrado biomes.

The prospecting of potential participants are done by snowball sampling.

The interviews consist of open and closed questions, and an interactive activity of building a DAG with the participants. The objective of developing DAGs with different participants is to explore a diversity of possibilities to theorize NVS causes. The use of DAGs before any modeling exercise (such as feature selection) is useful to reflect about the phenomena. It is also possible to compare DAGs (since they are graphs), so it will open an opportunity to explore convergences and divergences between participants.

::: {.callout-important collapse="true"}
READ:

-   https://doi.org/10.11157/fohpe.v20i3.387

-   https://doi.org/10.1177/1468794118781718

-   https://doi.org/10.1016/S0167-9236(03)00095-2

-   https://doi.org/10.1080/13645579.2021.1935565

-   https://doi.org/10.1080/13645579.2020.1766777

-   https://doi.org/10.1080/13645579.2018.1503400
:::

The questions aims to develop a context of the participant experience and perspectives on deforestation.

```{r}
#| label: tbl-schedule
#| tbl-cap: Interview schedule used in this project.
#| echo: false

htmltools::includeHTML("./figs/interview_schedule.html")

```

### Literature Assessment

The literature assessment provides information to the creation of the theoretical model, based on published results. However, it is performed as a complement to the reviews. The queries of the literature assessment are created based on reflections of the causal relationships identified in the interviews (e.g. if variable *A* is believed to cause *B*, what is the chain of events that allows this process?). Once the queries are created, a forward snowball search is performed, in which the resulting papers and its citing documents are screened.

```{mermaid}
%%| label: fig-review-diagram
%%| fig-cap: Workflow of literature review
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Questions] --> B[Query Development]
    A[Questions] --> C[Documents Screening]
    B[Query Development] --> D[Database Search]
    D[Database Search] --> C[Documents Screening]
    C[Documents Screening] --> E[Documents Collection]
    E[Documents Collection] --> F[Forward Snowball Search]
    F[Forward Snowball Search] --> C[Documents Screening]
    E[Documents Collection] --> G[Final Collection]

```

The relevant results from the literature are documented and stored for the creation of the theoretical model, in conjunction with the data acquired from the interviews.

### Variables description

The variables used in this project will serve to predict deforestation and its impacts on social and environmental dimensions. The variables may present diverse nature, such as quantitative and qualitative.

```{r}
#| label: tbl-variables
#| tbl-cap: Variables used in this project.
#| echo: false

htmltools::includeHTML("./figs/variables_table.html")

```

#### Biomes

The biomes limits are provided by IBGE. The extent of the biomes have been changing over the years, and since we are working on a time series, the extent will dependent on the year.

The downloaded data was filtered to contain only the limits of the Amazon and Cerrado biomes.

#### Deforestation

The deforestation variable is derived from the MapBiomas land use and land cover collection.

The downloaded data was cropped to the extent of the Cerrado and Amazon biomes. Than the raster data was aggregated to a coarser spatial resolution, from 30 to 300 meters, assigning the value of the most frequent class to the new pixel (the mode of the 100 pixels that will be aggregated to the 300 meters pixels). This was done to reduce the amount of observations, which would be unfeasible to process, since the original data consists of hundreds of billions pixels.

#### Conservation Units

The limits of the Conservation Units (UC) are provided by the Ministry of Environment and Climate Change. These are the conservation units that finished the registration process at the National Register of Conservation Units (CNUC). However, the data used in this project is accessed by the Institute for Applied Economic Research (IPEA), which organizes data in a standard attributes and spatial projection. The data is represented as spatial vectors.

The UC vectors are intersected to the base grid, and the area of each UC inside each cell is calculated.

#### Indigenous Lands

The limits of Indigenous Lands (IL) inside the Amazon and Cerrado are provided by FUNAI.

## Sociological Analysis

The sociological analysis is based on the theoretical model (created from the grounded theory), and it is performed according to the Field Theory of Bourdieu. The analysis consists on defining a social field, its social rules, social actors within the field, and the power relationships between the actors.

In this project, the social field is idealized as an arena where NVS is materialized, in which I name as Land Use and Cover Field (LUCF). This field is where disputes over land happens. The concept of LUCF is broad, and may contain diverse types of disputes, however, in this work it is bounded to disputes related to NVS.

The social rules dictate the disputes inside the LUCF, and are not restrained only by the politics institutions and devices.

Social actors are conceptualized as groups of interest that represents not only individuals that share a common culture and goals, but also institutions.

The power of the social actors can manifest in different ways, such as economic, political, symbolic, social and cultural power.

The sociological analysis will consist in identifying the social groups and their power in each of the causes of NVS (that were proposed in the theoretical model). The relationship between these social groups will also be characterized. From these information, the causal mechanisms of deforestation are discussed by. abducttion

::: {.callout-important collapse="true"}
READ:

-   <https://doi.org/10.1177/026327696013002001>

-   <https://doi.org/10.2752/152897999786690753>

-   <https://doi.org/10.1162/GLEP_a_00323>
:::

## Statistical Analysis

The statistical analysis is responsible for exploring relationships of observed variables within the exercise of predicting NVS. It is performed by structuring a database of observed variables that are considered to be a possible cause of the NVS, followed by a selection of variables according to the theoretical model, and finally the prediction of NVS.

### Database Structuring

The database contains data from different social and natural dimensions, which can be available in diverse formats and structures. To make the modeling process more efficient and transparent, all variables of interest must be organized coherently.

The process to create the database consists of accessing the data sources, downloading the data to the local environment, transforming and organizing the data to the grid, and store in the local environment.

```{mermaid}
%%| label: fig-data-diagram
%%| fig-cap: Mermaid diagram
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Data Source] --> E[Pre Processing]
    B[Base Grid] --> E[Pre Processing]
    E[Pre Processing] --> F[Gridded Data]
    F[Gridded Data] --> G[Database]

```

The data are stored in a nested directories database with hive-style partitioning. The database is composed of a collection of parquet files, a format with high compression, that facilitates processing large volumes of data. The main partition stores the variables, which means that each variable will be stored in a separate directory. If necessary, the data will be partitioned by further variables (as a rule of thumb, each parquet file should not be smaller than 20MB and not bigger than 2GB).

To structure a collection of data that presents different natures, I must transform all the variables into a standard grid system. The grid system will be composed of 0.2 degrees cells (40km x 40km), which should be a balanced compromise between detail and computational cost.

```{r}
#| label: fig-base-grid
#| fig-cap: "Model grid, in which variables were transformed to"
#| fig-asp: 1
#| echo: false

load("./figs/base_grid.rdata")

viz_grid

```

Each grid cell contains one observation, for each year, for all the variables. Only pixels that contained natural vegetation in the first year of the analysis will be considered valid.

### Model Development

The statistical model follow the standard approach to develop supervised models.

The variables selection will be performed according to available data of possible causes of NVS (as stated in the theoretical model), the selection will also be performed to remove variables that can induce unwanted bias in the results, such as colliders and mediators.

The data splitting between training and training, validation and testing groups will be performed in order to avoid spatial and temporal correlation between observations.

The parameters adjustments will be performed by cross validation methods for resampling and racing techniques for parameter optimization. In this process, validation data will be used for parameter adjustments.

After the final model fit, accuracy metrics will be calculated in order to estimate the error of the statistical model. Along with the accuracy assessment, a series of model interpretation techniques will be applied in order to understand the model results.

The main steps are shown in @fig-model-diagram.

```{mermaid}
%%| label: fig-model-diagram
%%| fig-cap: Mermaid diagram
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Database] --> B[Variables Selection]
    B[Variables Selection] --> C[Data Split]
    C[Data Split] --> D[Training Data]
    D[Training Data] --> E[Pre Processing]
    E[Pre Processing] --> F[Initial Model Fit]
    C[Data Split] --> G[Validation Data]
    C[Data Split] --> H[Test Data]
    F[Initial Model Fit] --> I[Parameters Adjustments]
    G[Validation Data] --> I[Parameters Adjustments]
    I[Parameters Adjustments] --> J[Final Model Fit]
    H[Test Data] --> K[Model Assessment]
    J[Final Model Fit] --> K[Model Assessment]
    J[Final Model Fit] --> L[Model Interpretation]
    K[Model Assessment] --> L[Model Interpretation]

```

::: {.callout-important collapse="true"}
READ: spatial models

-   <https://doi.org/10.3390/ijgi10090600>
-   <https://doi.org/10.1007/s00168-021-01101-x>

READ: causality for feature selection

-   <https://arxiv.org/pdf/2207.04053.pdf>
-   <https://doi.org/10.1145/3409382>

READ: variables related to deforestation

-   <https://doi.org/10.1371/journal.pone.0269729>
:::

## Results Interpretation

The interpretation of quantitative and qualitative results are performed by reflecting about the possible causal mechanisms of NVS.

# References {.unnumbered}