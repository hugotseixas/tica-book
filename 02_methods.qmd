# Methods {#sec-methods}

```{r}
#| label: libraries
#| include: false

library(gt)
library(lubridate)
library(tidyverse)

```

This project relies on developing a theoretical model of how and why Natural Vegetation Suppression (NVS) occurs persistently in the Amazon and Cerrado. This theoretical model is responsible to represent the mechanisms that causes the NVS. Based on the theoretical model, sociological and statistical analysis are performed to describe the causes of NVS from subjective and objective perspectives.

To employ the tasks above and accomplish the objectives (see @sec-objectives), the project is divided into four parts:

1.  Creation of the NVS theoretical model;

2.  Sociological assessment of agents related to the NVS theoretical model;

3.  Statistical analysis of data related to the NVS theoretical model;

4.  Interpretation of the results;

The first part is performed by conducting an adaptation of the Critical Realist Grounded Theory [@oliver-2011] method (which is itself an adaptation of the general Grounded Theory method). My adaptation combines the interactive engagement with data trough the acquisition and coding process, and the retroduction approach to infer causal mechanisms of NVS. The result of this process will be a theoretic model, represented by a Directed Acyclic Graph (DAG), which abstracts relationships of cause between variables.

In the second part, a sociological analysis describes how groups of interest are related to the variables from the NVS theoretical model, and what are the interactions between different groups, according to their actions and power status. The analysis will be based on Fields Theory of Bourdieu.

The third part contains the development and employment of statistical regression algorithms, that will be trained and tested using available data that are represented in the NVS theoretic model. The prediction of the models will be analyzed by machine learning interpretation techniques.

The fourth and last part is where results of both approaches (sociological and statistical analyses) will be interpreted in conjunction.

The sequence of activities that compose each part are represented in @fig-method-diagram, summarizing the method.

```{mermaid}
%%| label: fig-method-diagram
%%| fig-cap: "General workflow of the method. The activities that composes each part of the project are: (1) Literature Assessment, Experts Interviews, Theoretical Model; (2) Sociological Analysis; (3) Available Data, Database Structuring, Statistical Analysis; (4) Results Interpretation."
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Literature Assessment] --> B[Theoretical Model]
    C[Experts Interviews] --> B
    B --> D[Database Structuring]
    E[Available Data] --> D
    B --> F[Sociological Analysis]
    C --> G[Statistical Analysis]
    D --> G
    F --> H[Results Interpretation]
    G --> H

```

The combination of activities configures as a Convergent Parallel Mixed Method of research, where quantitative and qualitative analysis are perform at the same time, providing results to a final interpretation, However, the design of this work includes a previous establishment of a common theory that guides both analysis, so they share the same foundations.

In the next sections, each part of the work, and its respective activities are described.

## Theoretical Model

The theoretical model will be created by the employment of an adaptation of the Critical Realist Grounded Theory. The method of Grounded Theory is widely used in social sciences with the objective of generating theories, it consists of an interactive and concurrent process of data collection and analysis. It have been modified trough time to accommodate different paradigms of research, such as the Critical Realism.

The Critical Realist Grounded Theory introduces the necessity to explicitly account for the link between observations and their underlying generative mechanisms, and the use of retroduction in order to abstract these mechanisms [@oliver-2011].

The process of data acquisition is performed by a series of interviews and literature assessment. The interviews inquire possible causes of NVS and the social groups related to this phenomena. After each interview, the answers are coded into general terms, and with related question of how and why they can affect NVS. These questions are transformed into literature database queries, that helps finding written material that may enrich analysis with convergences or divergences with interview answers, or with new causes of NVS. After each round of interviews and literature assessment, the next interview may change to accommodate findings from the previous. This cyclic process is demonstrated in @fig-theoretical-diagram.

```{mermaid}
%%| label: fig-theoretical-diagram
%%| fig-cap: Workflow of theoretical model development
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Interview] --> B[Data]
    C[Questions] --> D[Literature Assessment]
    D --> E[Data]
    B --> F[Theoretical Model]
    F --> C
    E --> F
    F --> A

```

This process is repeated until the data from interviews and literature assessment starts to get redundant, adding little additional information to the theoretical model.

### Experts Interviews

The objective of the interviews is to explore a diverse range of possible causes of NVS, and its impacts on the environment and society.

The target participants are researchers with past experience on analyzing NVS in the Amazon or Cerrado biomes.

The prospecting of potential participants are done by snowball sampling.

The interviews consist of open and closed questions (see @sec-interview-schedule for the interview schedule), and an interactive activity of building a DAG with the participants (see @sec-interview-dag).

### Literature Assessment

The literature assessment provides information to the creation of the theoretical model, based on published results. However, it is performed as a complement to the reviews. The queries of the literature assessment are created based on reflections of the causal relationships identified in the interviews (e.g. if variable *A* is believed to cause *B*, what is the chain of events that allows this process?). Once the queries are created, a forward snowball search is performed, in which the resulting papers and its citing documents are screened.

```{mermaid}
%%| label: fig-review-diagram
%%| fig-cap: Workflow of literature review
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Questions] --> B[Query Development]
    A[Questions] --> C[Documents Screening]
    B[Query Development] --> D[Database Search]
    D[Database Search] --> C[Documents Screening]
    C[Documents Screening] --> E[Documents Collection]
    E[Documents Collection] --> F[Forward Snowball Search]
    F[Forward Snowball Search] --> C[Documents Screening]
    E[Documents Collection] --> G[Final Collection]

```

The relevant results from the literature are documented and stored for the creation of the theoretical model, in conjunction with the data acquired from the interviews.

## Sociological Analysis

The sociological analysis is based on the theoretical model (created from the grounded theory), and it is performed according to the Field Theory of Bourdieu. The analysis consists on defining a social field, its social rules, social actors within the field, and the power relationships between the actors.

In this project, the social field is idealized as an arena where NVS is materialized, in which I name as Land Use and Cover Field (LUCF). This field is where disputes over land happens. The concept of LUCF is broad, and may contain diverse types of disputes, however, in this work it is bounded to disputes related to NVS.

The social rules dictate the disputes inside the LUCF, and are not restrained only by the politics institutions and devices.

Social actors are conceptualized as groups of interest that represents not only individuals that share a common culture and goals, but also institutions.

The power of the social actors can manifest in different ways, such as economic, political, symbolic, social and cultural power.

The sociological analysis will consist in identifying the social groups and their power in each of the causes of NVS (that were proposed in the theoretical model). The relationship between these social groups will also be characterized. From these information, the causal mechanisms of deforestation are discussed by. abducttion

::: {.callout-important collapse="true"}
READ:

-   <https://doi.org/10.1177/026327696013002001>

-   <https://doi.org/10.2752/152897999786690753>

-   <https://doi.org/10.1162/GLEP_a_00323>
:::

## Statistical Analysis

The statistical analysis is responsible for exploring relationships of observed variables within the exercise of predicting NVS. It is performed by structuring a database of observed variables that are considered to be a possible cause of the NVS, followed by a selection of variables according to the theoretical model, and finally the prediction of NVS.

### Database Structuring

The database contains data from different social and natural dimensions, which can be available in diverse formats and structures. To make the modeling process more efficient and transparent, all variables of interest must be organized coherently.

The process to create the database consists of accessing the data sources, downloading the data to the local environment, transforming and organizing the data to the grid, and store in the local environment.

```{mermaid}
%%| label: fig-data-diagram
%%| fig-cap: Mermaid diagram
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Data Source] --> E[Pre Processing]
    B[Base Grid] --> E[Pre Processing]
    E[Pre Processing] --> F[Gridded Data]
    F[Gridded Data] --> G[Database]

```

The data are stored in a nested directories database with hive-style partitioning. The database is composed of a collection of parquet files, a format with high compression, that facilitates processing large volumes of data. The main partition stores the variables, which means that each variable will be stored in a separate directory. If necessary, the data will be partitioned by further variables (as a rule of thumb, each parquet file should not be smaller than 20MB and not bigger than 2GB).

To structure a collection of data that presents different natures, I must transform all the variables into a standard grid system. The grid system will be composed of 0.2 degrees cells (40km x 40km), which should be a balanced compromise between detail and computational cost.

```{r}
#| label: fig-base-grid
#| fig-cap: "Model grid, in which variables were transformed to"
#| fig-asp: 1
#| echo: false

load("./figs/base_grid.rdata")

viz_grid

```

Each grid cell contains one observation, for each year, for all the variables. Only pixels that contained natural vegetation in the first year of the analysis will be considered valid.

### Model Development

The statistical model follow the standard approach to develop supervised models.

```{mermaid}
%%| label: fig-model-diagram
%%| fig-cap: Mermaid diagram
%%| fig-responsive: true
%%| fig-align: center

flowchart TD
    A[Database] --> B[Variables Selection]
    B[Variables Selection] --> C[Data Split]
    C[Data Split] --> D[Training Data]
    D[Training Data] --> E[Pre Processing]
    E[Pre Processing] --> F[Initial Model Fit]
    C[Data Split] --> G[Validation Data]
    C[Data Split] --> H[Test Data]
    F[Initial Model Fit] --> I[Parameters Adjustments]
    G[Validation Data] --> I[Parameters Adjustments]
    I[Parameters Adjustments] --> J[Final Model Fit]
    H[Test Data] --> K[Model Assessment]
    J[Final Model Fit] --> K[Model Assessment]
    J[Final Model Fit] --> L[Model Interpretation]
    K[Model Assessment] --> L[Model Interpretation]

```

## Results Interpretation

# References {.unnumbered}